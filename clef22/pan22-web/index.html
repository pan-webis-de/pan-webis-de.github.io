---
layout: default
nav_active: events
title: PAN @ CLEF 2022
description: PAN @ CLEF 2022
---

<main>
    <div class="uk-section uk-section-default">
        <div class="uk-container">
            <h1 class="uk-margin-remove-top">PAN at CLEF 2022</h1>
            <ul class="uk-list">
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-tasks">Shared Tasks</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-important-dates">Important Dates</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-keynotes">Keynotes</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-program">Program</a></li>
<!--                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-sponsors">Sponsors</a></li>-->
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-organizing-committee">Organizing Committee</a></li>
            </ul>
        </div>

        <div class="uk-container uk-margin-medium">
            <h2 id="index-tasks" class="uk-margin-small-top">Shared Tasks</h2>
            <ul>
                <li><a href="{{ '/shared-tasks.html#authorship-verification' | relative_url }}">Authorship Verification</a></li>
                <li><a href="{{ '/shared-tasks.html#profiling-irony-spreaders-on-twitter' | relative_url }}">Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO)</a></li>
                <li><a href="{{ '/shared-tasks.html#style-change-detection' | relative_url }}">Style Change Detection</a></li>
            </ul>

            <h2 id="index-important-dates">Important Dates</h2>
            <ul>
                <li>tba: Early bird software submission phase (optional)</li>
                <li>tba: Software submission deadline</li>
                <li>tba: Participant paper submission
<!--                    [<a href="../../pan-paper-template.zip">template</a>]-->
<!--                    [<a href="http://clef2022.clef-initiative.eu/index.php?page=Pages/instructions_for_authors.html">guidelines</a> (use the PAN <a href="../../pan-paper-template.zip">template</a>)]-->
<!--                    [<a href="https://easychair.org/conferences/?conf=clef2021">submission</a>]-->
                </li>
                <li>tba: Peer review notification</li>
                <li>tba: Camera-ready participant papers submission</li>
                <li>tba: Early bird conference registration</li>
                <li>September 5-9, 2022: Conference</li>
            </ul>
            <p>The timezone of all deadlines is <a href="https://en.wikipedia.org/wiki/Anywhere_on_Earth">Anywhere on Earth</a>.</p>

            <h2 id="index-keynotes">Keynotes</h2>
            <div class="uk-grid uk-child-width-1-2@l" data-uk-grid>
                <div>The keynotes will be announced at a later date.</div>

<!--                <article class="keynote">-->
<!--                    <header class="keynote-header">-->
<!--                        <div class="keynote-speaker-image">-->
<!--                            <img src="{{ '/clef21/pan21-figures/arkaitz-zubiaga.jpg' | relative_url }}"-->
<!--                                 alt="Arkaitz Zubiaga">-->
<!--                        </div>-->
<!--                        <div class="keynote-meta">-->
<!--                            <div class="keynote-title">Generalisation in Social Media Research: from Fact Verification -->
<!--to Hate Speech Detection</div>-->
<!--                            <div class="keynote-speaker"><a href="http://www.zubiaga.org/" target="_blank">Arkaitz Zubiaga</a></div>-->
<!--                            <div class="keynote-affiliation">Queen Mary University of London</div>-->
<!--                        </div>-->
<!--                    </header>-->
<!--                    <div class="keynote-body">-->
<!--                        <p>While models built and tested on a specific dataset and for a specific -->
<!--                            task often achieve very good performance, they then fail to generalise -->
<!--                            when they are applied to new, unseen data. In this talk I will discuss -->
<!--                            the importance and challenges of achieving generalisable performance -->
<!--                            in social media research with a particular focus on fact verification -->
<!--                            and hate speech detection. I will present some of our recent work in -->
<!--                            this direction, as well as discuss open challenges to further the -->
<!--                            capacity of generalisation especially in hate speech detection.-->
<!--                        </p>-->

<!--                        <footer>-->
<!--                            <div class="keynote-bio" id="keynote-bio-1">-->
<!--                                <p>Arkaitz Zubiaga is a lecturer at Queen Mary University of London, -->
<!--                                    where he leads the Social Data Science lab. His research interests -->
<!--                                    revolve around computational social science and natural language -->
<!--                                    processing, with a focus on linking online data with events in the -->
<!--                                    real world, among others for tackling problematic issues on the Web -->
<!--                                    and social media that can have a damaging effect on individuals or -->
<!--                                    society at large, such as hate speech, misinformation, inequality, -->
<!--                                    biases and other forms of online harm.</p>-->

<!--                                <a href="#" class="read-more" data-uk-toggle="target: #keynote-bio-1; cls: expanded">Read-->
<!--                                    more&hellip;</a>-->
<!--                                <a href="#" class="read-less" data-uk-toggle="target: #keynote-bio-1; cls: expanded">Read-->
<!--                                    less&hellip;</a>-->
<!--                            </div>-->
<!--                        </footer>-->
<!--                    </div>-->
<!--                </article>-->
<!--                <article class="keynote">-->
<!--                    <header class="keynote-header">-->
<!--                        <div class="keynote-speaker-image">-->
<!--                            <img src="{{ '/clef21/pan21-figures/maarten-sap.jpg' | relative_url }}"-->
<!--                                 alt="Maarten Sap">-->
<!--                        </div>-->
<!--                        <div class="keynote-meta">-->
<!--                            <div class="keynote-title">Detecting and Rewriting Socially Biased Language</div>-->
<!--                            <div class="keynote-speaker"><a href="https://homes.cs.washington.edu/~msap/" target="_blank">Maarten Sap</a></div>-->
<!--                            <div class="keynote-affiliation">University of Washington</div>-->
<!--                        </div>-->
<!--                    </header>-->
<!--                    <div class="keynote-body">-->
<!--                      <p>Language has the power to reinforce stereotypes and project social -->
<!--                        biases onto others, either through overt hate or subtle biases. -->
<!--                        Accounting for this toxicity and social bias in language is crucial -->
<!--                        for natural language processing (NLP) systems to be safely and -->
<!--                        ethically deployed in the world.-->
<!--                        In this talk, I will first analyze a failure case of automatic hate -->
<!--                        speech detection, in which we find that models tend to flag speech by -->
<!--                        African Americans as toxic more often than by others. We trace the -->
<!--                        origins of the biases back to the annotated datasets, and show that we -->
<!--                        can reduce these biases, by making a tweet's dialect more explicit -->
<!--                        during the annotation process.-->
<!--                        Then, as an alternative to binary hate speech detection, I will -->
<!--                        present Social Bias Frames, a new structured formalism for distilling -->
<!--                        biased implications of language. Using a new corpus of 150k structured -->
<!--                        annotations, we show that models can learn to reason about high-level -->
<!--                        offensiveness of statements, but struggle to explain why a statement -->
<!--                        might be harmful.-->
<!--                        Finally, I will introduce PowerTransformer, a new unsupervised model -->
<!--                        for controllable debiasing of text through the lens of connotation -->
<!--                        frames of power and agency. With this model, we show that subtle -->
<!--                        gender biases in how characters are portrayed in stories and movies -->
<!--                        can be mitigated through automatic rewriting. I will conclude with -->
<!--                        future directions for better reasoning about toxicity and social -->
<!--                          biases in language.</p>-->
<!--                        <footer>-->
<!--                            <div class="keynote-bio" id="keynote-bio-2">-->
<!--                                <p>Maarten Sap is a postdoc/young investigator at the Allen Institute for -->
<!--                                AI (AI2) on project MOSAIC, and will join CMU's LTI department as an -->
<!--                                assistant professor in Fall 2022. His research focuses on making NLP -->
<!--                                systems socially intelligent, and understanding social inequality and -->
<!--                                bias in language. He has presented his work in top-tier NLP and AI -->
<!--                                conferences, receiving a best short paper nomination at ACL 2019 and a -->
<!--                                best paper award at the WeCNLP 2020 summit. Additionally, he and his -->
<!--                                team won the inaugural 2017 Amazon Alexa Prize, a social chatbot -->
<!--                                competition.-->
<!--                                He received his PhD from the University of Washington's Paul G. Allen -->
<!--                                School of Computer Science & Engineering where he was advised by Yejin -->
<!--                                Choi and Noah Smith. In the past, he has interned at the Allen -->
<!--                                Institute for AI working on social commonsense reasoning, and at -->
<!--                                Microsoft Research working on deep learning models for understanding -->
<!--                                human cognition.</p>-->

<!--                                <a href="#" class="read-more" data-uk-toggle="target: #keynote-bio-2; cls: expanded">Read-->
<!--                                    more&hellip;</a>-->
<!--                                <a href="#" class="read-less" data-uk-toggle="target: #keynote-bio-2; cls: expanded">Read-->
<!--                                    less&hellip;</a>-->
<!--                            </div>-->
<!--                        </footer>-->


<!--                    </div>-->
<!--                </article>-->

            </div>

            <h2 id="index-program">Program</h2>
            The program will be announces closer to the conference.
<!--            <p>PAN's program is part of the <a href="http://clef2022.clef-initiative.eu/index.php?page=Pages/programme.html">CLEF 2022 conference program</a>.</p>-->
<!--            <p style="color:red">Please note that all session times below are given in Bucharest time, i.e. GMT+3</p>-->

            <h2 id="index-organizing-committee">Organizing Committee</h2>
            <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                {% include people-cards/potthast.html %}
                {% include people-cards/rosso.html %}
                {% include people-cards/stamatatos.html %}
                {% include people-cards/stein.html %}
            </div>
            <div class="uk-container uk-padding-large uk-padding-remove-bottom">
                {% include organizations/clef-organizations-section.html year=2022 %}
            </div>
        </div>
    </div>
</main>
