---
layout: default
nav_active: events
title: PAN at CLEF 2022
description: PAN at CLEF 2022
---
<nav class="uk-container">
<ul class="uk-breadcrumb">
<li><a href="../../index.html">PAN</a></li>
<li><a href="../../events.html">Events</a></li>
<li class="uk-disabled"><a href="#">PAN at CLEF 2022</a></li>
</ul>
</nav>

<main>
    <div class="uk-section uk-section-default">
        <div class="uk-container">
            <h1 class="uk-margin-remove-top">PAN at CLEF 2022</h1>
            <ul class="uk-list">
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-tasks">Shared Tasks</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-important-dates">Important Dates</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-keynotes">Keynotes</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-program">Program</a></li>
<!--                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-sponsors">Sponsors</a></li>-->
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-organizing-committee">Organizing Committee</a></li>
            </ul>
        </div>

        <div class="uk-container uk-margin-medium">
            <h2 id="index-tasks" class="uk-margin-small-top">Shared Tasks</h2>
            <ul>
                <li><a href="{{ '/shared-tasks.html#authorship-verification' | relative_url }}">Authorship Verification</a></li>
                <li><a href="{{ '/shared-tasks.html#profiling-irony-spreaders-on-twitter' | relative_url }}">Profiling Irony and Stereotype Spreaders on Twitter (IROSTEREO)</a></li>
                <li><a href="{{ '/shared-tasks.html#style-change-detection' | relative_url }}">Style Change Detection</a></li>
                <li><a href="{{ '/shared-tasks.html#trigger-detection' | relative_url }}">Trigger Detection</a></li>
            </ul>

            <h2 id="index-important-dates">Important Dates</h2>
            <ul>
                <li>April 26, Early bird software submission phase (optional)</li>
                <li>May 24, Software submission deadline</li>
                <li>May 27, 2022: Participant paper submission
<!--                    [<a href="../../pan-paper-template.zip">template</a>]-->
<!--                    [<a href="http://clef2022.clef-initiative.eu/index.php?page=Pages/instructions_for_authors.html">guidelines</a> (use the PAN <a href="../../pan-paper-template.zip">template</a>)]-->
<!--                    [<a href="https://easychair.org/conferences/?conf=clef2021">submission</a>]-->
                </li>
                <li>June 13, 2022: Peer review notification</li>
                <li>July 1, 2022: Camera-ready participant papers submission</li>
                <li>tba: Early bird conference registration</li>
                <li>September 5-9, 2022: Conference</li>
            </ul>
            <p>The timezone of all deadlines is <a href="https://en.wikipedia.org/wiki/Anywhere_on_Earth">Anywhere on Earth</a>.</p>

<!--            <h2 id="index-keynotes">Keynotes</h2>
            <div class="uk-grid uk-child-width-1-2@l" data-uk-grid>
            <div>The keynotes will be announced at a later date.</div> -->
            <h2 id="index-keynotes">Keynotes</h2>
            <div class="uk-grid uk-child-width-1-2@l" data-uk-grid>

                <article class="keynote">
                    <header class="keynote-header">
                        <div class="keynote-speaker-image">
                            <img src="{{ '/clef22/pan22-figures/lara-fontanella.jpg' | relative_url }}"
                                 alt="Lara Fontanella">
                        </div>
                        <div class="keynote-meta">
                            <div class="keynote-title">Stereotyping: explanation and fallacies from a probabilistic and statistical perspective.</div>
                            <!-- <div class="keynote-speaker"><a href="" target="_blank">Lara Fontanella</a> -->
                            <div class="keynote-speaker">Lara Fontanella</div>
                            <div class="keynote-affiliation">University G. D'Annunzio Chieti-Pescara, Italy</div>
                        </div>
                    </header>
                    <div class="keynote-body">
                        <p>
                         Broadly speaking, stereotypes are features perceived to be associated with particular categories of people, and stereotyping corresponds to the characterisation of a group of people as sharing the same behaviours and attributes. According to the economic approach, stereotypes are beliefs about a group member in terms of the aggregate statistical distribution of group traits. In the sociological approach, stereotypes are described as oversimplified, derogatory and fundamentally incorrect generalisations about social groups. Finally, in the social cognition approach, stereotypes are seen as special cases of cognitive schemas: limited-capacity human minds create shortcuts via judgmental heuristics that result in savings on cognitive resources. These judgments are based on data of limited validity, processed according to heuristic rules, that might lead to biased conclusions. More recently, the investigation of stereotype formation and function has been explored in the framework of Bayesian predictive processing. Learning for the predictive brain involves testing predictions by using the data obtained from the world and applying Bayes’ theorem to develop probabilities. According to this learning process, instead of conceptualising stereotypes as a problem of the cognitive bias of the individual, it can be sustained that they should be viewed as “culture in mind”, influencing the cognition of cultural group members. In this talk, I will discuss statistical aspects of the stereotyping process and its biases and present some results of our research on stereotypes.
                        </p>
                        <!--
                        <footer>
                            <div class="keynote-bio" id="keynote-bio-1">
                                <p>Short Bio</p>

                                <a href="#" class="read-more" data-uk-toggle="target: #keynote-bio-1; cls: expanded">Read
                                    more&hellip;</a>
                                <a href="#" class="read-less" data-uk-toggle="target: #keynote-bio-1; cls: expanded">Read
                                    less&hellip;</a>
                            </div>
                        </footer>
                        -->
                    </div>
                </article>

                <article class="keynote">
                    <header class="keynote-header">
                        <div class="keynote-speaker-image">
                            <img src="{{ '/clef22/pan22-figures/viviana-patti.png' | relative_url }}"
                                 alt="Viviana Patti">
                        </div>
                        <div class="keynote-meta">
                            <div class="keynote-title">Fast and furious: when irony meets hatred and prejudice in social media.</div>
                            <!-- <div class="keynote-speaker"><a href="" target="_blank">Viviana Patti</a></div> -->
                            <div class="keynote-speaker">Viviana Patti</div>
                            <div class="keynote-affiliation">University of Turin, Italy</div>
                        </div>
                    </header>
                     
                    <div class="keynote-body">
                        <p>A variety of typologies of figurative messages can be recognised in social media: from irony to sarcastic posts, and to facetious tweets that can be playful, aimed at amusing or at strengthening ties with other users. In the last decade, irony and sarcasm have been proven to be pervasive in social media, posing a challenge to sentiment analysis systems. 
They are creative linguistic phenomena where affect-related aspects play a key role. They can influence and twist the affect of an utterance in complex and different ways, they can elicit various affective reactions, and can behave differently with respect to the polarity reversal phenomenon. Recently, awareness of the importance of automatically detecting irony and other figures of speech to correctly recognise hate speech in social media has grown, hand in hand with the need to create computational models capable of going under the shallow and identifying implicit and indirect expressions of abuse, where the the main challenges are related, on the one hand, to the use of figurative devices (i.e., irony and sarcasm), on the other hand, to the recall of inner ideologies (i.e., sexist ideology) and cognitive schemas (i.e., stereotypes). In fact, in case of negative and hateful opinions, social media users may tend to be less explicit, employing irony and sarcasm in their claims, in order to limit their exposure. In particular, sarcasm - a sharp and very effective form of irony used for mocking and ridiculing a victim - often recurs in hateful messages, lowering the social cost of what has been said. 
Identifying such indirect and implicit forms characterising hate speech is crucial not only to gain a richer understanding of the phenomena, but also because they often increase the viral load of the hate message (and its dangerousness or the possibility of fuelling a hate campaign): users sharing such contents do so with more levity when the message does not contain explicit insults. 
On this line, from a computational linguistics perspective, it is interesting to study how to make abusive language detection systems sensitive to implicit expressions of hate, and how the injection of linguistic (and affective) knowledge into the detection models can be useful to capture such implicit levels of meaning, with the final aim of investigating whether  awareness of the presence of irony and sarcasm increase the performance of abusive language detection systems.</p>
                        <!--
                        <footer>
                            <div class="keynote-bio" id="keynote-bio-2">
                                <p>Short Bio</p>

                                <a href="#" class="read-more" data-uk-toggle="target: #keynote-bio-2; cls: expanded">Read
                                    more&hellip;</a>
                                <a href="#" class="read-less" data-uk-toggle="target: #keynote-bio-2; cls: expanded">Read
                                    less&hellip;</a>
                            </div>
                        </footer>
                        -->
                    </div>
                </article>

       
                
                

<!--                <article class="keynote">-->
<!--                    <header class="keynote-header">-->
<!--                        <div class="keynote-speaker-image">-->
<!--                            <img src="{{ '/clef21/pan21-figures/arkaitz-zubiaga.jpg' | relative_url }}"-->
<!--                                 alt="Arkaitz Zubiaga">-->
<!--                        </div>-->
<!--                        <div class="keynote-meta">-->
<!--                            <div class="keynote-title">Generalisation in Social Media Research: from Fact Verification -->
<!--to Hate Speech Detection</div>-->
<!--                            <div class="keynote-speaker"><a href="http://www.zubiaga.org/" target="_blank">Arkaitz Zubiaga</a></div>-->
<!--                            <div class="keynote-affiliation">Queen Mary University of London</div>-->
<!--                        </div>-->
<!--                    </header>-->
<!--                    <div class="keynote-body">-->
<!--                        <p>While models built and tested on a specific dataset and for a specific -->
<!--                            task often achieve very good performance, they then fail to generalise -->
<!--                            when they are applied to new, unseen data. In this talk I will discuss -->
<!--                            the importance and challenges of achieving generalisable performance -->
<!--                            in social media research with a particular focus on fact verification -->
<!--                            and hate speech detection. I will present some of our recent work in -->
<!--                            this direction, as well as discuss open challenges to further the -->
<!--                            capacity of generalisation especially in hate speech detection.-->
<!--                        </p>-->

<!--                        <footer>-->
<!--                            <div class="keynote-bio" id="keynote-bio-1">-->
<!--                                <p>Arkaitz Zubiaga is a lecturer at Queen Mary University of London, -->
<!--                                    where he leads the Social Data Science lab. His research interests -->
<!--                                    revolve around computational social science and natural language -->
<!--                                    processing, with a focus on linking online data with events in the -->
<!--                                    real world, among others for tackling problematic issues on the Web -->
<!--                                    and social media that can have a damaging effect on individuals or -->
<!--                                    society at large, such as hate speech, misinformation, inequality, -->
<!--                                    biases and other forms of online harm.</p>-->

<!--                                <a href="#" class="read-more" data-uk-toggle="target: #keynote-bio-1; cls: expanded">Read-->
<!--                                    more&hellip;</a>-->
<!--                                <a href="#" class="read-less" data-uk-toggle="target: #keynote-bio-1; cls: expanded">Read-->
<!--                                    less&hellip;</a>-->
<!--                            </div>-->
<!--                        </footer>-->
<!--                    </div>-->
<!--                </article>-->
<!--                <article class="keynote">-->
<!--                    <header class="keynote-header">-->
<!--                        <div class="keynote-speaker-image">-->
<!--                            <img src="{{ '/clef21/pan21-figures/maarten-sap.jpg' | relative_url }}"-->
<!--                                 alt="Maarten Sap">-->
<!--                        </div>-->
<!--                        <div class="keynote-meta">-->
<!--                            <div class="keynote-title">Detecting and Rewriting Socially Biased Language</div>-->
<!--                            <div class="keynote-speaker"><a href="https://homes.cs.washington.edu/~msap/" target="_blank">Maarten Sap</a></div>-->
<!--                            <div class="keynote-affiliation">University of Washington</div>-->
<!--                        </div>-->
<!--                    </header>-->
<!--                    <div class="keynote-body">-->
<!--                      <p>Language has the power to reinforce stereotypes and project social -->
<!--                        biases onto others, either through overt hate or subtle biases. -->
<!--                        Accounting for this toxicity and social bias in language is crucial -->
<!--                        for natural language processing (NLP) systems to be safely and -->
<!--                        ethically deployed in the world.-->
<!--                        In this talk, I will first analyze a failure case of automatic hate -->
<!--                        speech detection, in which we find that models tend to flag speech by -->
<!--                        African Americans as toxic more often than by others. We trace the -->
<!--                        origins of the biases back to the annotated datasets, and show that we -->
<!--                        can reduce these biases, by making a tweet's dialect more explicit -->
<!--                        during the annotation process.-->
<!--                        Then, as an alternative to binary hate speech detection, I will -->
<!--                        present Social Bias Frames, a new structured formalism for distilling -->
<!--                        biased implications of language. Using a new corpus of 150k structured -->
<!--                        annotations, we show that models can learn to reason about high-level -->
<!--                        offensiveness of statements, but struggle to explain why a statement -->
<!--                        might be harmful.-->
<!--                        Finally, I will introduce PowerTransformer, a new unsupervised model -->
<!--                        for controllable debiasing of text through the lens of connotation -->
<!--                        frames of power and agency. With this model, we show that subtle -->
<!--                        gender biases in how characters are portrayed in stories and movies -->
<!--                        can be mitigated through automatic rewriting. I will conclude with -->
<!--                        future directions for better reasoning about toxicity and social -->
<!--                          biases in language.</p>-->
<!--                        <footer>-->
<!--                            <div class="keynote-bio" id="keynote-bio-2">-->
<!--                                <p>Maarten Sap is a postdoc/young investigator at the Allen Institute for -->
<!--                                AI (AI2) on project MOSAIC, and will join CMU's LTI department as an -->
<!--                                assistant professor in Fall 2022. His research focuses on making NLP -->
<!--                                systems socially intelligent, and understanding social inequality and -->
<!--                                bias in language. He has presented his work in top-tier NLP and AI -->
<!--                                conferences, receiving a best short paper nomination at ACL 2019 and a -->
<!--                                best paper award at the WeCNLP 2020 summit. Additionally, he and his -->
<!--                                team won the inaugural 2017 Amazon Alexa Prize, a social chatbot -->
<!--                                competition.-->
<!--                                He received his PhD from the University of Washington's Paul G. Allen -->
<!--                                School of Computer Science & Engineering where he was advised by Yejin -->
<!--                                Choi and Noah Smith. In the past, he has interned at the Allen -->
<!--                                Institute for AI working on social commonsense reasoning, and at -->
<!--                                Microsoft Research working on deep learning models for understanding -->
<!--                                human cognition.</p>-->

<!--                                <a href="#" class="read-more" data-uk-toggle="target: #keynote-bio-2; cls: expanded">Read-->
<!--                                    more&hellip;</a>-->
<!--                                <a href="#" class="read-less" data-uk-toggle="target: #keynote-bio-2; cls: expanded">Read-->
<!--                                    less&hellip;</a>-->
<!--                            </div>-->
<!--                        </footer>-->


<!--                    </div>-->
<!--                </article>-->

            </div>

            <h2 id="index-program">Program</h2>
            The program will be announces closer to the conference.
<!--            <p>PAN's program is part of the <a href="http://clef2022.clef-initiative.eu/index.php?page=Pages/programme.html">CLEF 2022 conference program</a>.</p>-->
<!--            <p style="color:red">Please note that all session times below are given in Bucharest time, i.e. GMT+3</p>-->

            <h2 id="index-organizing-committee">Organizing Committee</h2>
            <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                {% include people-cards/potthast.html %}
                {% include people-cards/rosso.html %}
                {% include people-cards/stamatatos.html %}
                {% include people-cards/stein.html %}
            </div>
            <div class="uk-container uk-padding-large uk-padding-remove-bottom">
                {% include organizations/clef-organizations-section.html year=2022 %}
            </div>
        </div>
    </div>
</main>
