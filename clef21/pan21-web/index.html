---
layout: default
nav_active: events
title: PAN @ CLEF 2021
description: PAN @ CLEF 2021
---

<main>
    <div class="uk-section uk-section-default">
        <div class="uk-container">
            <h1 class="uk-margin-remove-top">PAN at CLEF 2021</h1>
            <ul class="uk-list">
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-tasks">Shared Tasks</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-important-dates">Important Dates</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-keynotes">Keynotes</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-program">Program</a></li>
<!--                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-sponsors">Sponsors</a></li>-->
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#index-organizing-committee">Organizing Committee</a></li>
            </ul>
        </div>

        <div class="uk-container uk-margin-medium">
            <h2 id="index-tasks" class="uk-margin-small-top">Shared Tasks</h2>
            <ul>
                <li><a href="{{ '/shared-tasks.html#authorship-verification' | relative_url }}">Authorship Verification</a></li>
                <li><a href="{{ '/shared-tasks.html#profiling-hate-speech-spreaders-on-twitter' | relative_url }}">Profiling Hate Speech Spreaders on Twitter</a></li>
                <li><a href="{{ '/shared-tasks.html#style-change-detection' | relative_url }}">Style Change Detection</a></li>
            </ul>

            <h2 id="index-important-dates">Important Dates</h2>
            <ul>
                <li><b>April 07, 2021 (extended)</b>: Early bird software submission phase (optional)</li>
                <li><b>April to Mid-May</b>: Software submission phase</li>
                <li><b>May 20, 2021</b>: Software submission deadline</li>
                <li><b>May 28, 2021</b>: Participant paper submission
                    [<a href="../../pan-paper-template.zip">template</a>]
                    [<a href="http://clef2021.clef-initiative.eu/index.php?page=Pages/instructions_for_authors.html">guidelines</a> (use the PAN <a href="../../pan-paper-template.zip">template</a>)]
                    [<a href="https://easychair.org/conferences/?conf=clef2021">submission</a>]
                </li>
                <li><b>June 11, 2021</b>: Peer review notification</li>
                <li><b>June 30, 2021</b>: Camera-ready participant papers submission</li>
                <li><b>TBD</b>: Early bird conference registration</li>
                <li>September 21-24, 2021: Conference</li>
            </ul>
            <p>The timezone of all deadlines is <a href="https://en.wikipedia.org/wiki/Anywhere_on_Earth">Anywhere on Earth</a>.</p>

            <h2 id="index-keynotes">Keynotes</h2>
            <div class="uk-grid uk-child-width-1-2@l" data-uk-grid>
                <!--<div>The keynotes will be announced at a later date.</div>-->


                <article class="keynote">
                    <header class="keynote-header">
                        <div class="keynote-speaker-image">
                            <img src="{{ '/clef21/pan21-figures/arkaitz-zubiaga.jpg' | relative_url }}"
                                 alt="Arkaitz Zubiaga">
                        </div>
                        <div class="keynote-meta">
                            <div class="keynote-title">Generalisation in Social Media Research: from Fact Verification 
to Hate Speech Detection</div>
                            <div class="keynote-speaker"><a href="http://www.zubiaga.org/" target="_blank">Arkaitz Zubiaga</a></div>
                            <div class="keynote-affiliation">Queen Mary University of London</div>
                        </div>
                    </header>
                    <div class="keynote-body">
                        <p>While models built and tested on a specific dataset and for a specific 
                            task often achieve very good performance, they then fail to generalise 
                            when they are applied to new, unseen data. In this talk I will discuss 
                            the importance and challenges of achieving generalisable performance 
                            in social media research with a particular focus on fact verification 
                            and hate speech detection. I will present some of our recent work in 
                            this direction, as well as discuss open challenges to further the 
                            capacity of generalisation especially in hate speech detection.
                        </p>

                        <footer>
                            <div class="keynote-bio" id="keynote-bio-1">
                                <p>Arkaitz Zubiaga is a lecturer at Queen Mary University of London, 
                                    where he leads the Social Data Science lab. His research interests 
                                    revolve around computational social science and natural language 
                                    processing, with a focus on linking online data with events in the 
                                    real world, among others for tackling problematic issues on the Web 
                                    and social media that can have a damaging effect on individuals or 
                                    society at large, such as hate speech, misinformation, inequality, 
                                    biases and other forms of online harm.</p>

                                <!--<a href="#" class="read-more" data-uk-toggle="target: #keynote-bio-1; cls: expanded">Read
                                    more&hellip;</a>
                                <a href="#" class="read-less" data-uk-toggle="target: #keynote-bio-1; cls: expanded">Read
                                    less&hellip;</a>-->
                            </div>
                        </footer>
                    </div>
                </article>

 
                <article class="keynote">
                    <header class="keynote-header">
                        <div class="keynote-speaker-image">
                            <img src="{{ '/clef21/pan21-figures/maarten-sap.jpg' | relative_url }}"
                                 alt="Maarten Sap">
                        </div>
                        <div class="keynote-meta">
                            <div class="keynote-title">Detecting and Rewriting Socially Biased Language</div>
                            <div class="keynote-speaker"><a href="https://homes.cs.washington.edu/~msap/" target="_blank">Maarten Sap</a></div>
                            <div class="keynote-affiliation">University of Washington</div>
                        </div>
                    </header>
                    <div class="keynote-body">
                      <p>Language has the power to reinforce stereotypes and project social 
                        biases onto others, either through overt hate or subtle biases. 
                        Accounting for this toxicity and social bias in language is crucial 
                        for natural language processing (NLP) systems to be safely and 
                        ethically deployed in the world.
                        In this talk, I will first analyze a failure case of automatic hate 
                        speech detection, in which we find that models tend to flag speech by 
                        African Americans as toxic more often than by others. We trace the 
                        origins of the biases back to the annotated datasets, and show that we 
                        can reduce these biases, by making a tweet's dialect more explicit 
                        during the annotation process.
                        Then, as an alternative to binary hate speech detection, I will 
                        present Social Bias Frames, a new structured formalism for distilling 
                        biased implications of language. Using a new corpus of 150k structured 
                        annotations, we show that models can learn to reason about high-level 
                        offensiveness of statements, but struggle to explain why a statement 
                        might be harmful.
                        Finally, I will introduce PowerTransformer, a new unsupervised model 
                        for controllable debiasing of text through the lens of connotation 
                        frames of power and agency. With this model, we show that subtle 
                        gender biases in how characters are portrayed in stories and movies 
                        can be mitigated through automatic rewriting. I will conclude with 
                        future directions for better reasoning about toxicity and social 
                          biases in language.</p>
                        <footer>
                            <div class="keynote-bio" id="keynote-bio-1">
                                <p>Maarten Sap is a postdoc/young investigator at the Allen Institute for 
                                AI (AI2) on project MOSAIC, and will join CMU's LTI department as an 
                                assistant professor in Fall 2022. His research focuses on making NLP 
                                systems socially intelligent, and understanding social inequality and 
                                bias in language. He has presented his work in top-tier NLP and AI 
                                conferences, receiving a best short paper nomination at ACL 2019 and a 
                                best paper award at the WeCNLP 2020 summit. Additionally, he and his 
                                team won the inaugural 2017 Amazon Alexa Prize, a social chatbot 
                                competition.
                                He received his PhD from the University of Washington's Paul G. Allen 
                                School of Computer Science & Engineering where he was advised by Yejin 
                                Choi and Noah Smith. In the past, he has interned at the Allen 
                                Institute for AI working on social commonsense reasoning, and at 
                                Microsoft Research working on deep learning models for understanding 
                                human cognition.</p>

                                <!--<a href="#" class="read-more" data-uk-toggle="target: #keynote-bio-1; cls: expanded">Read
                                    more&hellip;</a>
                                <a href="#" class="read-less" data-uk-toggle="target: #keynote-bio-1; cls: expanded">Read
                                    less&hellip;</a>-->
                            </div>
                        </footer>


                    </div>
                </article>

            </div>

            <h2 id="index-program">Program</h2>
                The workshop program will be announced at a later date.
<!--            <p>PAN's program is part of the <a href="https://clef2020.clef-initiative.eu/index.php?page=Pages/programme.html">CLEF conference program</a>.</p>-->
<!--
            <table class="uk-table uk-table-divider uk-table-small uk-table-striped">
                <thead>
                </thead>
                <tfoot>
                <tr>
                    <td colspan="2"><span style="display:none">.</span></td>
                </tr>
                </tfoot>
                <tbody>
                <tr>
                    <td colspan="2"><b>September 24</b></td>
                </tr>
                <tr>
                    <td>11:00-12:30</td>
                    <td><b>Keynote Session</b>, Chair: Paolo Rosso [<a href="https://us02web.zoom.us/j/82188876931?pwd=K1Z5eStEWlQreGZ3WHFyUXBGVFJUQT09" target="_blank">zoom</a>]</td>
                </tr>
                <tr>
                    <td></td>
                    <td>Misinformation Detection in Online Social Networks<br>
                        <i>Anastasia Giachanou</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Presentation and Award Ceremony<br>
                        <i>Symanto</i></td>
                </tr>
                <tr>
                    <td>15:00-16:30</td>
                    <td><b>Plenary Session: Lab Overview</b> [<a href="https://us02web.zoom.us/j/89080780119?pwd=STVKRWtpL3cyaTdYdlZTL2x5MzBkZz09" target="_blank">zoom</a>]</td>
                </tr>
                <tr>
                    <td></td>
                    <td>Overview of PAN 2020: Authorship Verification, Celebrity Profiling, Profiling Fake News Spreaders on Twitter, and Style Change Detection<br>
                        <i>Janek Bevendorff, Bilal Ghanem, Anastasia Giachanou, Mike Kestemont, Enrique Manjavacas, Ilia Markov, Maximilian Mayerl, Martin Potthast, Francisco Rangel, Paolo Rosso, Günther Specht, Efstathios Stamatatos, Benno Stein, Matti Wiegmann, and Eva Zangerle</i>
                    </td>
                </tr>
                <tr>
                    <td>17:00-18:30</td>
                    <td><b>Lab Session: Profiling Fake News Spreaders on Twitter</b>, Chair: Francisco Rangel [<a href="https://us02web.zoom.us/j/84928458820?pwd=aE9nbGphc2FCdVF1RW1DZFNObVN6QT09" target="_blank">zoom</a>]</td>
                </tr>
                <tr>
                    <td></td>
                    <td>Overview of the Profiling Fake News Spreaders on Twitter Task at PAN 2020<br>
                        <i>Francisco Rangel, Bilal Ghanem, Anastasia Giachanou, Paolo Rosso</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>An Ensemble Model Using N-grams and Statistical Features to Identify Fake News Spreaders on Twitter<br>
                        <i>Jakab Buda and Flora Bolonyai</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Detecting Fake News Spreaders in Social Networks via Linguistic and Personality Features<br>
                        <i>Anu Shrestha, Francesca Spezzano and Abishai Joy</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Proling Fake News Spreaders: Stylometry, Personality, Emotions and Embeddings.<br>
                        <i>Elisabetta Fersini, Justin Armanini and Michael D'Intorni</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Analyzing User Profiles for Detection of Fake News Spreaders on Twitter<br>
                        <i>María S. Espinosa, Roberto Centeno and Álvaro Rodrigo</i></td>
                </tr>
                <tr>
                    <td colspan="2"><b>September 25</b></td>
                </tr>
                <tr>
                    <td>09:00-10:30</td>
                    <td><b>Lab Session: Authorship Verification</b>, Chair: Mike Kestemont [<a href="https://us02web.zoom.us/j/88535819933?pwd=bVdscjJ6aFBScE9iN1kxSGJvaGMvQT09" target="_blank">zoom</a>]</td>
                </tr>
                <tr>
                    <td></td>
                    <td>Overview of the Authorship Verification Task at PAN 2020<br>
                        <i>Mike Kestemont, Enrique Manjavacas, Ilia Markov, Janek Bevendorff, Matti Wiegmann, Efstathios Stamatatos, Martin Potthast, and Benno Stein</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Deep Bayes Factor Scoring for Authorship Verification<br>
                        <i>Benedikt Boenninghoff, Julian Rupp, Robert M. Nickel, and Dorothea Kolossa</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Feature Vector Difference based Neural Network and Logistic Regression Models for Authorship Verification<br>
                        <i>Janith Weerasinghe and Rachel Greenstadt</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Siamese Network applied to Authorship Verification<br>
                        <i>Emir Araujo-Pino, Helena Gómez-Adorno, and Gibran Fuentes-Pineda</i></td>
                </tr>
                <tr>
                    <td>15:00-16:30</td>
                    <td><b>Lab Session: Celebrity Profiling and Style Change Detection </b>, Chairs: Matti Wiegmann and Eva Zangerle [<a href="https://us02web.zoom.us/j/85832327924?pwd=UzZRRjhFZ0ErU0RRRVlLdXkyemw1dz09" target="_blank">zoom</a>]</td>
                </tr>
                <tr>
                    <td></td>
                    <td>Overview of the Celebrity Profiling Task at PAN 2020<br>
                        <i>Matti Wiegmann, Benno Stein, and Martin Potthast</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Celebrity Profiling using Twitter Follower Feeds<br>
                        <i>Abigail Hodge and Samantha Price</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Know your Neighbors: Efficient Author Profiling via Follower Tweets<br>
                        <i>Boshko Koloski, Senja Pollak and Blaž Škrlj</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Overview of the Style Change Detection Task at PAN 2020<br>
                        <i>Eva Zangerle, Maximilian Mayerl, Günther Specht, Benno Stein, and Martin Potthast</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Style Change Detection Using BERT<br>
                        <i>Aarish Iyer and Soroush Vosoughi</i></td>
                </tr>

                <tr>
                    <td>17:00-18:30</td>
                    <td><b>Lab Session: Profiling Fake News Spreaders on Twitter</b>, Chair: Francisco Rangel [<a href="https://us02web.zoom.us/j/85832327924?pwd=UzZRRjhFZ0ErU0RRRVlLdXkyemw1dz09" target="_blank">zoom</a>]</td>
                </tr>
                <tr>
                    <td></td>
                    <td>RMIT at PAN-CLEF 2020: Profiling Fake News Spreaders on Twitter<br>
                        <i>Xinhuan Duan, Elham Naghizade, Damiano Spina and Xiuzhen Zhang</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Detecting Fake News Spreaders on Twitter Using Universal Sentence Encoder<br>
                        <i> Soumayan Bandhu Majumder and Dipankar Das</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Multilingual Detection of Fake News Spreaders via Sparse Matrix Factorization<br>
                        <i>Boshko Koloski, Senja Pollak and Blaž Škrlj</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Fake News Spreaders Profiling Through Behavioural Analysis<br>
                        <i>Matteo Cardaioli, Stefano Cecconello, Mauro Conti, Luca Pajola and Federico Turrin</i></td>
                </tr>
                <tr>
                    <td></td>
                    <td>Using N-grams to detect Fake News Spreaders on Twitter<br>
                        <i>Juan Pizarro</i></td>
                </tr>
                </tbody>
            </table>
-->

            <h2 id="index-organizing-committee">Organizing Committee</h2>
            <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                {% include people-cards/potthast.html %}
                {% include people-cards/rosso.html %}
                {% include people-cards/stamatatos.html %}
                {% include people-cards/stein.html %}
            </div>
            <div class="uk-container uk-padding-large uk-padding-remove-bottom">
                {% include organizations/clef-organizations-section.html year=2021 %}
            </div>
        </div>
    </div>
</main>
