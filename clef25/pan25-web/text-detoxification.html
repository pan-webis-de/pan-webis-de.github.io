---
layout: default
nav_active: shared-tasks
title: PAN at CLEF 2025 - Multilingual Text Detoxification
description: PAN at CLEF 2025 - Multilingual Text Detoxification
---

<head>
<style>
     table {
         border-collapse: collapse; /* Ensures that borders are shared between cells */
         width: 100%; /* Optional: Makes the table take up the full width of its container */
     }
     th, td {
         border: 1px solid black; /* Adds borders to table headers and cells */
         padding: 10px; /* Increases padding for more space within cells */
         text-align: left; /* Aligns text to the left */
     }
</style>
</head>

<nav class="uk-container">
   <ul class="uk-breadcrumb">
      <li><a href="../../index.html">PAN</a></li>
      <li><a href="../../shared-tasks.html">Shared Tasks</a></li>
      <li class="uk-disabled"><a href="#">Multilingual Text Detoxification 2025</a></li>
   </ul>
</nav>
<main class="uk-section uk-section-default">
   <div class="uk-container">
      <div class="uk-container uk-margin-small">
         <div>
            <h1 class="uk-margin-remove-top">Multilingual Text Detoxification (TextDetox) 2025</h1>
            <ul class="uk-list">
               <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#synopsis">Synopsis</a></li>
               <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#task">Task</a></li>
               <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#phases">Phases</a></li>
               <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#methodology">Methodology</a></li>
               <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#data">Data</a></li>
               <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#evaluation">Evaluation</a></li>
               <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#submission">Submission</a></li>
               <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#dates">Important Dates</a></li>
               <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#related-work">Related Work</a></li>
               <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#task-committee">Task Committee</a></li>
            </ul>
         </div>
         <div style="position:absolute;right:50px; top: 300px;">
            <p>Stop the war!</p>
            <b>Sponsored by</b><br/>
            <a href="https://toloka.ai/" target="_blank">
            <img src="../pan25-figures/toloka-logo.png" style="width: 200px" alt="Toloka">
            </a>
         </div>
      </div>
      <div class="uk-container uk-margin-medium">
         <h2 id="synopsis">Synopsis</h2>
         <ul>
             <li>Task: Given a toxic piece of text, re-write it in a non-toxic way while saving the main content as much as possible.</li>
            <li>Input: toxic sentences in <b>15 languages</b> from all over the globe: English, Spanish, German, Chinese, Arabic, Hindi, Ukrainian, Russian, Amharic, Italian, French, Hebrew, Hinglish, Japanese, and Tatar. [<a href="https://huggingface.co/datasets/textdetox/multilingual_paradetox">data</a>]
            </li>
            <li>Output: detoxified version of the text in the corresponding language.
            </li>
            <li>Evaluation: automatic and manual evaluation based on three parameters: style transfer accuracy; content preservation; fluency.[<a href="https://github.com/pan-webis-de/pan-code/tree/master/clef25/text-detoxification">baselines</a>]
            </li>
            <li>Submission: [<a href="https://codalab.lisn.upsaclay.fr/competitions/22396">CodaLab</a>] is now open!
            </li>
            <li>
               Registration: [<a href="https://clef2025.clef-initiative.eu/index.php?page=Pages/registration.html">CLEF2025 Registration</a>]
            </li>
            <li>
               Contact: [<a href="https://huggingface.co/textdetox">HuggingFace space</a>][<a href="https://groups.google.com/g/textdetox-clef2025">google group</a>]
            </li>
            <li>
               Paper submission link: tba.
            </li>
            <li>
               Paper template: tba.
            </li>
         </ul>
         <h2 id="task">Task</h2>
         <p>
            Identification of toxicity in user texts is an active area of research. Today, social networks such as <a href="https://edition.cnn.com/2021/06/16/tech/facebook-ai-conflict-moderation-groups/index.html">Facebook</a>, <a href="https://about.instagram.com/blog/announcements/introducing-new-tools-to-protect-our-community-from-abuse">Instagram</a> are trying to address the problem of toxicity.
            However, they usually simply block such kinds of texts. 
            We suggest a proactive reaction to toxicity from the user. Namely, we aim at presenting a neutral version of a user message which preserves meaningful content. We denote this task as <i>text detoxification</i>.
         </p>
         <p>
            <img src="../pan25-figures/textdetox_abstract.jpg" style="width: 1100px; display: block; margin: 0 auto;" alt="Multilingual TextDetox Task">
         </p>
         <p>
            More text detoxification examples in English:
         <table>
            <tr>
               <th>Toxic</th>
               <th>Detoxified</th>
            </tr>
            <tr>
               <td>he had steel b*lls too!</td>
               <td>he was brave too!</td>
            </tr>
            <tr>
               <td>delete the page and sh*t up</td>
               <td>delete the page</td>
            </tr>
            <tr>
               <td>what a chicken cr*p excuse for a reason.</td>
               <td>what a bad excuse for a reason.</td>
            </tr>
         </table>
         </p>

         <p>
              <b>Languages</b>
         </p>
         <p>
            In this competition, we suggest you create detoxification systems for various languages from several linguitic families. We have languages from the <a href='https://pan.webis.de/clef24/pan24-web/text-detoxification.html'>2024 edition</a> — English, Spanish, German, Chinese, Arabic, Hindi, Ukrainian, Russian, and Amharic — 
            together with <b>new languages</b>: European languages — Italian, French, Turkic language Tatar, Semitic language Hebrew, Asian language Japanese, and even one very popular code-switch language Hinglish!
         </p>

         <p>
            <b>Definition of toxiciy</b> 
         </p>
         <p>
            One of the crucial points in this task is to have a common ground on how to estimate if the text is toxic or not. 
            In our task, we will work only with <b>explicit</b> types of toxicity—obvious present of obscene and rude lexicon where still there is meaningful neutral content present—and <b>do not</b> work with <b>implicit</b> types—like sarcasm, passive aggressiveness, or direct hate to some group where no neutral content can be found.
            Such implicit toxicity types are challenging to be detoxified so the intent will indeed become non-toxic.
            For this reason, we tried to pick for our datasets the sentences with explicit toxicity where we can detoxify it.
            However, toxicity can be quite a subjective intent. We hope, that we will agree on the majority of the cases what should be toxic or not. In the end, the main goal is to make the texts and the world at least somehow less toxic ;)
         </p>

         <h2 id="phases">Phases</h2>
         The shared task will be divided into two phases — development and test. In both phases, we are make the emphasis on <b>cross-lingual</b> and <b>multilingual</b> text detoxification.
         <p>
            <b>Development Phase</b> The <a href='https://huggingface.co/datasets/textdetox/multilingual_paradetox'>parallel traning data</a> is available for these languages: English, Spanish,  German, Chinese, Arabic, Hindi, Ukrainian, Russian, and Amharic. 
            In our <a href='https://huggingface.co/datasets/textdetox/multilingual_paradetox_test'>test set</a>, we have 600 toxic sentence per these languages together with 100 toxic sentence for new languages—Italian, French, Hebrew, Hinglish, Japanese, and Tatar! 
            Your task will be to come up with text detoxification models for new languages with no parallel training data as well as aiming to have the best overall multilingual model.
         </p>
         <p>
            <b>Test Phase</b> We will add even more test toxic sentences for new languages!
         </p>

         <h2 id="methodology">Methodology</h2>
          <p>
            <b>Supervised Methods</b>
         </p>
         <p>
            If a parallel corpus of toxic-neutral pairs is already available, then you can fine-tune <i>any</i> text generation model.
            You can refer to the ruT5 model for detoxification <a href="https://github.com/s-nlp/russe_detox_2022/tree/main/baselines/t5">example</a> from the <a href="https://russe.nlpub.org/2022/tox/">shared task</a> at the <a href="https://www.dialog-21.ru/en/evaluation/">Dialogue Evaluation</a> forum.
         </p>
        <p>
             We provide one of the top solution from TextDetox2024 <a href='https://huggingface.co/s-nlp/mt0-xl-detox-orpo'>mT0-XL-detox</a> and <a href='https://huggingface.co/textdetox/mbart-detox-baseline'>mBART</a> baselines fine-tuned on 9 languages.
        </p>
         <p>
            <b>Baselines</b>
         </p>
         <p>
            <img src="../pan25-figures/detox_baselines.png" style="width: 700px; display: block; margin: 0 auto;" alt="Unsupervised Baselines">
         </p>
         We provide three baselines:
         <ol>
            <li>
               <b>Duplicate</b>: a simple duplication of the toxic input.
            </li>
            <li>
               <b>Delete</b>: elimination of a toxic keywords based on a predifined <a href="https://huggingface.co/datasets/textdetox/multilingual_toxic_lexicon">dictionary</a> for each language.
            </li>
            <li>
               <b>Backtranslation</b>: a more sophisticated cross-lingual transfer method. Translate the input to the language for which powerful detoxification model in available, perform detoxification, and translate back to the target language.
               The translation is done with NLLB-600M <a href="https://huggingface.co/facebook/nllb-200-distilled-600M">model</a>, detoxification with English bart-base-detox <a href="https://huggingface.co/s-nlp/bart-base-detox">model</a>.
            </li>
            <li>
                 <b>LLMs prompting</b>: for sure, you can utilize any LLMs in zero-shot or few-shot format. As a baseline, we provide zero-shot results of <a href='https://huggingface.co/mlabonne/Llama-3.1-70B-Instruct-lorablated'>LLaMa-70B</a> prompting.
            </li>
         </ol>
         The code for all baselines is available <a href="https://github.com/pan-webis-de/pan-code/tree/master/clef25/text-detoxification">here</a>.
           
         <h2 id="data">Data</h2>
        <p>
             <b>Training Data</b>
        </p>
         <ol>
            <li><b>Parallel Text Detoxification Dataset</b> The <a href="https://huggingface.co/datasets/textdetox/multilingual_paradetox">link</a> to the parallel multilingual text detoxification data. This dataset contains 400 pairs for each of 9 languages.</li>
            <li><b>Toxicity Classification Dataset</b>. To support broader experiments with toxicity, we provide a compilation of <a href='https://huggingface.co/datasets/textdetox/multilingual_toxicity_dataset'>toxicity classification data</a> for all 15 languages.</li>
            <li><b>Toxic Keywords List</b>. <a href='https://huggingface.co/datasets/textdetox/multilingual_toxic_lexicon'>Toxic keywords</a> for all 15 languages and <a href='https://huggingface.co/datasets/textdetox/multilingual_toxic_spans'>toxic spans</a> for 9 languages.</li>
         </ol>
         <p>
              <b>Test Data</b>
         </p>
         <p>
              The test data for all languages is available [<a href='https://huggingface.co/datasets/textdetox/multilingual_paradetox_test'>here</a>].
         </p>

         <h2 id="evaluation">Evaluation</h2>
         <p>
            For the whole competition, the automatic evaluation metrics set will be available. We provide the multilingual automatic evaluation pipeline based on main three parameters:
         <ul>
            <li>
               <b>Style Transfer Accuracy</b>: Given the generated paraphrase, classify its level of <b>non-toxicity</b>. For this, specifically fine-tuned xlm-roberta-large for toxicity binary <a href="https://huggingface.co/textdetox/xlmr-large-toxicity-classifier-v2">classification</a> is used.            </li>
            <li>
               <b>Content preservation</b>: Given two texts, evaluate the similarity of their content. We calculate it as cosine similarity between <a href="https://huggingface.co/sentence-transformers/LaBSE">LaBSe</a> embeddings.
            </li>
            <li>
               <b>Fluency</b>: To estimate the adequacy of the text and its similarity to the human-written detoxified references, we use <a href="https://huggingface.co/myyycroft/XCOMET-lite">xCOMET</a> model. Based on our experiments, COMET machine translation models showed perfect correlation with the annotation of fluency in detoxified texts.
            </li>
         </ul>
         </p>
         <p>
            Each metric component lies in the range [0;1]. To have the one common metric for leaderboard estimation, we will calculate <b>Joint</b> metric as the mean of combination of <b>STA</b>*<b>SIM</b>*<b>FL</b> per sample.
         </p>
         <p>
            <img src="../pan25-figures/detox_evaluation_formula.jpeg" style="width: 650px; display: block; margin: 0 auto;" alt="The concept of text detoxification evaluation">
         </p>
         <p>
              <b>[2025-edition metrics update]</b> As you can compare from 2024 shared task edition, the calculation of J score advanced significantly (see the formula). Thus, in each metrics parameter--STA, SIM, and FL--we take take into account human references.
              For <b>STA</b>, we check not only the probability of a new output to be a non-toxic sentence, but also if its non-toxicity score is less than human references. This is motivated by the fact that even human detoxifications might be not ideally non-toxic. For <b>SIM</b>, we calculate the weighted sum of output's similarity to the original sentence as well as the human detoxification. Finally, machine-translation inspired fluency metric xCOMET evaluates the similarity of the output to the human-written detoxified version.
         </p>
         <p>
               <b>Automatic Evaluatiom Code</b> is fully publicly available [<a href="https://github.com/pan-webis-de/pan-code/tree/master/clef25/text-detoxification">here</a>].
         </p>

         <h2 id="submission">Submission</h2>
         <p>
            All submissions are handled through <a href="https://codalab.lisn.upsaclay.fr/competitions/22396" target="_blank">Codalab</a>.
            We accept solutions submissions.
            Please follow carefully the corresponding instructions.
         </p>

         <h2 id="dates">Important Dates</h2>
         <ol>
              <li><b>Registration to CLEF2025</b>: is now open! Register <a href='https://clef2025.clef-initiative.eu/index.php?page=Pages/registration.html'>here</a> and join our <a href='https://groups.google.com/g/textdetox-clef2025'>Google Group</a>.</li>
              <li>April 25, 2025: Registration closes.</li>
              <li>May 1st, 2025: Test phase starts.</li>
              <li>May 10, 2025: End of evaluation cycle.</li>
              <li>May 30, 2025: Participants paper submission.</li>
              <li>June 27, 2025: Notification of acceptance.</li>
              <li>July 7, 2025: Camera-ready due.</li>
              <li>September 9-12, 2025: CLEF Conference in Madrid, Spain!</li>
         </ol>

         <!-- <h2 id="results">Results</h2>
         tba. -->
         
         <h2 id="related-work">Related Work</h2>
         <ol>
            <li>
               Dementieva D. et al. <b>Methods for Detoxification of Texts for the Russian Language</b>. Multimodal Technologies and Interaction 5, 2021. [<a href="https://www.mdpi.com/2514-4088/5/9/54/pdf">pdf</a>]
            </li>
            <li>
               Dale D. et. al. <b>Text Detoxification using Large Pre-trained Neural Models</b>. EMNLP, 2021. [<a href="https://aclanthology.org/2021.emnlp-main.629.pdf">pdf</a>]
            </li>
            <li>
               Logacheva V. et al. <b>ParaDetox: Detoxification with Parallel Data</b>. ACL, 2022. [<a href="https://aclanthology.org/2022.acl-long.469.pdf">pdf</a>]
            </li>
            <li>
               Dementieva D. et al. <b>RUSSE-2022: Findings of the First Russian Detoxification Shared Task Based on Parallel Corpora</b>. Dialogue, 2022. [<a href="https://www.dialog-21.ru/media/5755/dementievadplusetal105.pdf">pdf</a>]
            </li>
            <li>
               Logacheva, V. et al. <b>A Study on Manual and Automatic Evaluation for Text Style Transfer: The Case of Detoxification</b>. HumEval, 2022. [<a href="https://aclanthology.org/2022.humeval-1.8.pdf">pdf</a>]
            </li>
            <li>
               Dementieva, D. et al. <b>Exploring Methods for Cross-lingual Text Style Transfer: The Case of Text Detoxification</b>. AACL, 2023. [<a href="http://www.afnlp.org/conferences/ijcnlp2023/proceedings/main-long/cdrom/pdf/2023.ijcnlp-long.70.pdf">pdf</a>]
            </li>
            <li>
               Dementieva, D. et al. <b>Overview of the multilingual text detoxification task at pan 2024</b>. CLEF, 2024. [<a href="https://ceur-ws.org/Vol-3740/paper-223.pdf">pdf</a>]
            </li>
            <li>
               Dementieva, D. et al. <b>Multilingual and Explainable Text Detoxification with Parallel Corpora</b>. COLING, 2025. [<a href="https://arxiv.org/abs/2412.11691">pdf</a>]
            </li>
         </ol>
         
         <h2>Contributors</h2>
         We have a very big international team working on this Shared Task preparation. The following researchers are contributing to the parallel data preparation:
         <ul>
            <li>Daryna Dementieva: Ukrainian, English, Russian</li>
            <li>Nikolay Babakov: Ukrainian, Spanish</li>
            <li>Seid Yimam: Amharic</li>
            <li>Abinew Ali Ayele: Amharic</li>
            <li>Ashaf Elnagar: Arabic</li>
            <li>Xintong Wang: Chinese</li>
            <li>Naquee Rizwan: Hindi, Hinglish</li>
            <li>Caroline Brune: French</li>
            <li>Debora Nozza: Italian</li>
            <li>Sotaro Takeshita: Japanese</li>
            <li>Ilseyar Alimova: Tatar</li>
            <li>Chaya Liebeskind: Hebrew</li>
            <li>Shehryaar Shah Khan: Hinglish</li>
         </ul>
         <p>
              Vitaly Protasov contributed with new automatic evaluation metrics and leaderboard preparations.
         </p>
         <h2 id="task-committee">Task Committee</h2>
         <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
            {% include people-cards/dementieva.html %}
            {% include people-cards/babakov.html %}
            {% include people-cards/wang.html %}
            {% include people-cards/yimam.html %}
            {% include people-cards/rizwan.html %}
            {% include people-cards/elnagar.html %}
            {% include people-cards/brun.html %}
            {% include people-cards/chirkova.html %}
            {% include people-cards/muti.html %}
            {% include people-cards/nozza.html %}
            {% include people-cards/takeshita.html %}
            {% include people-cards/panchenko.html %}
         </div>
         <div class="uk-container uk-padding-large uk-padding-remove-bottom">
            {% include organizations/clef-organizations-section.html year=2025 %}
         </div>
      </div>
   </div>
</main>
