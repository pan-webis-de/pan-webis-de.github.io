---
layout: default
nav_active: shared-tasks
title: PAN at CLEF 2013 - Authorship Verification
description: PAN at CLEF 2013 - Authorship Verification
---
<nav class="uk-container">
<ul class="uk-breadcrumb">
<li><a href="../../index.html">PAN</a></li>
<li><a href="../../shared-tasks.html">Shared Tasks</a></li>
<li class="uk-disabled"><a href="#">Authorship Verification 2013</a></li>
</ul>
</nav>

<main>
    <div class="uk-section uk-section-default">
        <div class="uk-container uk-margin-small">
            <h1 class="uk-margin-remove-top">Authorship Verification 2013</h1>
            <ul class="uk-list">
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#synopsis">Synopsis</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#introduction">Introduction</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#task">Task</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#input">Input</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#output">Output</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#evaluation">Evaluation</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#results">Results</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#related-work">Related Work</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#task-committee">Task Committee</a></li>
            </ul>
        </div>

        <div class="uk-container uk-margin-medium">

            <h2 id="synopsis">Synopsis</h2>
            <ul>
                <li>Task: Given two documents, are they written by the same author?</li>
                <li>Input: [<a href="{{ 'data.html#pan13-verification' | relative_url }}">data</a>]</li>
                <li>Submission: [<a href="https://www.tira.io/task/author-identification/">submit</a>]</li>
            </ul>

            <h2 id="introduction">Introduction</h2>
            <p>Authorship attribution is an important problem in many areas including information retrieval and
            computational linguistics, but also in applied areas such as law and journalism where knowing
            the author of a document (such as a ransom note) may be able to save lives. The most common
            framework for testing candidate algorithms is a text classification problem: given known sample
            documents from a small, finite set of candidate authors, which if any wrote a questioned
            document of unknown authorship? It has been commented, however, that this may be an unreasonably
            easy task. A more demanding problem is author verification where given a set of documents by a
            single author and a questioned document, the problem is to determine if the questioned document
            was written by that particular author or not. This may more accurately reflect real life in the
            experiences of professional forensic linguists, who are often called upon to answer this kind of
            question. It is the second year PAN focuses on the so-called author verification problem.</p>
            <p><strong>A note to forensic linguists:</strong> In order to bridge the gap between linguistics and
            computer science, we strongly encourage submissions from researchers from both fields. We
            understand that research groups with expertise in linguistics use manual or semi-automated
            methods and, therefore, they are not able to submit their software. To enable their
            participation, we will provide them with the opportunity to analyze the test corpus after the
            deadline of software submission (mid-April). Their results will be ranked in a separate list
            with respect to the performance of the software submissions and they will be entitled to
            describe their approach in a paper. In this framework, any scholar or research group with expertise in
            linguistics wishing to participate should contact the Task Chair.</p>


            <h2 id="task">Task</h2>
            <p>
            Given a small set (no more than 5, possibly as few as one) of "known" documents by a single
            person and a "questioned" document, the task is to determine whether the questioned document was
            written by the same person who wrote the known document set.</p>


            <h2 id="input">Input</h2>
            <p>To develop your software, we provide you with a training corpus that comprises a set of known
            documents by a single person and exactly one questioned document. There are several such problem
            instances covering English, Greek, and Spanish and a varying number of known documents (1-10 per
            problem). All documents within a single problem instance will be in the same language and best
            efforts are applied to assure that within-problem documents are matched for genre, register,
            theme, and date of writing. The document lengths vary from a few hundred to a few thousand
            words.
            <a target="_blank" href="https://www.uni-weimar.de/medien/webis/events/pan-13/pan13-papers-final/pan13-authorship-verification/juola13-overview.pdf#page=3">
                Learn more</a>
            </p>


            <h2 id="output">Output</h2>
            <p>Your software must take as input the absolute path to a set of problems. For each problem there
            is a separate sub-folder within that path including the set of known documents and the single
            unknown document of that problem. The software has to output a single text file <code>answers.txt</code>
            with all the produced answers for the whole set of evaluation problems. Each line of this file
            corresponds to a problem instance, it starts with the ID of the problem followed by a binary
            (Y)ES/(N)O answer to the question "Is the unknown document written by the author of the known
            documents?". If you do not want to provide answers for some problems, you can either replace the
            answer character with "-" or just do not include a line for that problem to your answers. For
            example, an <code>answers.txt</code> file may look like this:</p>
            <pre class="prettyprint lang-py" style="overflow-x:auto">
EN01 Y
EN02 N
EN03 -
EN04 Y
EN07 Y
...
</pre>
            <p>Optionally, you may also provide a score, a real number in the set [0,1] inclusive, where 0
            corresponds to NO and 1 to YES. This score should be round with two decimal digits and will
            allow a more detailed evaluation of your approach. In this case, the scores have to be placed
            next to the binary answers. It is possible to provide scores even for problems you are not able
            to provide binary answers. For example, an <code>answers.txt</code> file with scores may look
            like this:</p>
            <pre class="prettyprint lang-py">
EN01 Y 0.90
EN02 N 0.25
EN03 - 0.53
EN04 Y 0.86
EN07 Y 0.74
...
</pre>
            <p>Use a single whitespace to separate problem ID, binary answer, and score. The naming of the
            output file is up to you. We reccomend to use the name of the participant group-run.</p>


            <h2 id="evaluation">Evaluation</h2>
            <p>Performance of the binary classification will be measured as follows:</p>
            <ul>
                <li>Recall = #correct_answers / #problems</li>
                <li>Precision = #correct_answers / #answers</li>
            </ul>
            <p>Participants are be ranked by combining these measures via F1.
            In addition, participants may also provide a score, a real number in the set [0,1] inclusive,
            where 0 corresponds to NO and 1 to YES. A separate ranking for those participants who also
            submit real scores [0,1] according to the ROC-AUC. For the calculation of ROC curves, any
            missing answers are assumed to be wrong answers.</p>


            <h2 id="results">Results</h2>
            <table class="uk-table uk-table-divider uk-table-small uk-table-hover">
                <tbody>
                <tr>
                    <td>0.753</td>
                    <td>Shachar Seidman<br/>Bar Ilan University, Israel</td>
                </tr>
                <tr>
                    <td>0.718</td>
                    <td>Oren Halvani, Martin Steinebach, and Ralf Zimmermann<br/>Fraunhofer Institute for Secure
                        Information Technology SIT, Germany
                    </td>
                </tr>
                <tr>
                    <td>0.671</td>
                    <td>Robert Layton, Paul Watters, and Richard Dazeley<br/>University of Ballarat, Australia
                    </td>
                </tr>
                <tr>
                    <td>0.671</td>
                    <td>Timo Petmanson<br/>University of Tartu, Estonia</td>
                </tr>
                <tr>
                    <td>0.659</td>
                    <td>Magdalena Jankowska, Vlado Kešelj, and Evangelos Milios<br/>Dalhousie University, Canada
                    </td>
                </tr>
                <tr>
                    <td>0.659</td>
                    <td>Darnes Vilariño, David Pinto, Helena Gómez, Saúl León, and Esteban Castillo<br/>Benemérita
                        Universidad Autónoma de Puebla, Mexico
                    </td>
                </tr>
                <tr>
                    <td>0.655</td>
                    <td>Victoria Bobicev<br/>Technical University of Moldova, Moldova</td>
                </tr>
                <tr>
                    <td>0.647</td>
                    <td>Vanessa Wei Feng and Graeme Hirst<br/>University of Toronto, Canada</td>
                </tr>
                <tr>
                    <td>0.612</td>
                    <td>Paola Ledesma°, Gibran Fuentes*, Gabriela Jasso*, Angel Toledo*, and Ivan Meza*<br/>°Escuela
                        Nacional de Antropología e Historia (ENAH) and *Universidad Nacional Autónoma de México
                        (UNAM), Mexico
                    </td>
                </tr>
                <tr>
                    <td>0.606</td>
                    <td>M.R. Ghaeini<br/>Amirkabir University of Technology, Iran</td>
                </tr>
                <tr>
                    <td>0.600</td>
                    <td>Michiel van Dam<br/>Delft University of Technology, The Netherlands</td>
                </tr>
                <tr>
                    <td>0.600</td>
                    <td>Erwan Moreau and Carl Vogel<br/>Trinity College Dublin, Ireland</td>
                </tr>
                <tr>
                    <td>0.576</td>
                    <td>Arun Jayapal and Binayak Goswami<br/>Nuance Communications, India</td>
                </tr>
                <tr>
                    <td>0.553</td>
                    <td>Cristian Grozea° and Marius Popescu*<br/>°Fraunhofer FIRST, Germany, and *University of
                        Bucharest, Romania
                    </td>
                </tr>
                <tr>
                    <td>0.541</td>
                    <td>Anna Vartapetiance and Lee Gillam<br/>University of Surrey, UK</td>
                </tr>
                <tr>
                    <td>0.529</td>
                    <td>Roman Kern<br/>Know-Center GmbH, Austria</td>
                </tr>
                <tr>
                    <td>0.500</td>
                    <td>Baseline</td>
                </tr>
                <tr>
                    <td>0.417</td>
                    <td>Cor J. Veenman° and Zhenshi Li*<br/>°Netherlands Forensic Institute and *Delft
                        University of Technology, The Netherlands
                    </td>
                </tr>
                <tr>
                    <td>0.331</td>
                    <td>Sorin Fratila<br/>University Politehnica of Bucharest, Romania</td>
                </tr>
                </tbody>
            </table>
            <p>A more detailed analysis of the detection performances can be found in the overview paper
                accompanying this task.</p>

            <h2 id="related-work">Related Work</h2>
            <ul>
                <li>
                    <a href="{{ 'publications.html#?q=2012%20juola' | relative_url }}">Author Identification, PAN @ CLEF'12</a>
                </li>
                <li>
                    <a href="{{ 'publications.html#?q=2011%20argamon' | relative_url }}">Author Identification, PAN @ CLEF'11</a>
                </li>
                <li>
                    Patrick Juola. <a href="http://portal.acm.org/citation.cfm?id=1373451">Authorship Attribution</a>.
                    In Foundations and Trends in Information Retrieval, Volume 1, Issue 3, March 2008.
                </li>
                <li>
                    Moshe Koppel, Jonathan Schler, and Shlomo Argamon.
                    <a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.20961/full">
                        Computational Methods Authorship Attribution</a>.
                    Journal of the American Society for Information Science and Technology, Volume 60, Issue 1, pages 9-26, January 2009.
                </li>
                <li>
                    Efstathios Stamatatos. <a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.21001/full">
                        A Survey of Modern Authorship Attribution Methods</a>.
                    Journal of the American Society for Information Science and Technology, Volume 60, Issue 3, pages 538-556, March 2009.
                </li>
            </ul>


            <h2 id="task-committee">Task Committee</h2>
            <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                    {% include people-cards/juola.html %}
                    {% include people-cards/argamon.html %}
                    {% include people-cards/koppel.html %}
            </div>
            <div class="uk-container uk-padding-large uk-padding-remove-bottom">
                {% include organizations/clef-organizations-section.html year=2013 %}
            </div>

        </div>  <!-- section -->
    </div>  <!-- section -->
</main>
