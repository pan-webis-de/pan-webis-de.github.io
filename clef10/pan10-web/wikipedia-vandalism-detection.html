---
layout: default
nav_active: tasks
title: PAN @ CLEF 2010 - Wikipedia Vandalism detection
description: PAN @ CLEF 2010 - Wikipedia Vandalism detection
---

<main>
    <header class="uk-section uk-section-muted">
        <nav class="uk-container">
            <div class="uk-align-right uk-visible@m uk-text-muted">
                <a class="uk-button" data-uk-icon="chevron-left" disabled></a>
                CLEF 2010
                <a class="uk-button uk-padding-remove-right"
                   href="{{ 'clef11/pan11-web/wikipedia-vandalism-detection.html' | relative_url }}"
                   data-uk-icon="chevron-right"></a>
            </div>

            <ul class="uk-text-muted uk-tab uk-margin-remove-top">
                <li><a href="{{ '/clef10/pan10-web/index.html' | relative_url }}">Overview</a></li>
                <li><a disabled>Keynotes</a></li>
                <li><a href="{{ '/clef10/pan10-web/program.html' | relative_url }}">Program</a></li>
                <li class="uk-active">
                    <a href="#">Tasks <span class="uk-margin-small-left"
                                            data-uk-icon="icon: chevron-down"></span></a>
                    <div class="uk-dropdown" data-uk-dropdown="mode: click">
                        <ul class="uk-nav uk-dropdown-nav">
                            <li class="uk-active"><a
                                    href="{{ '/clef10/pan10-web/wikipedia-vandalism-detection.html' | relative_url }}">
                                Wikipedia Vandalism Detection</a></li>
                            <li><a
                                    href="{{ '/clef10/pan10-web/plagiarism-detection.html' | relative_url }}">Plagiarism
                                Detection</a></li>
                        </ul>
                    </div>
                </li>
                <li><a href="{{ '/clef10/pan10-web/submission.html' | relative_url }}">Submission</a></li>
                <li><a href="{{ '/clef10/pan10-web/proceedings.html' | relative_url }}">Proceedings</a></li>
            </ul>
        </nav>

        <div class="uk-container uk-margin-small">
            {% include current-register-quicklink.html year=2010 %}
            <h1 class="uk-margin-small">Wikipedia Vandalism detection</h1>
            <div class="page-header-meta">PAN @ CLEF 2010</div>
            <p class="uk-text-lead">
                The <a href="http://en.wikipedia.org/wiki/Wikipedia:Vandalism" target="_blank">definition of
                vandalism</a> at Wikipedia includes "any addition, removal, or change of content made in a deliberate
                attempt to compromise the integrity of Wikipedia." Hence, Wikipedia vandalism detection comprises the
                following classification task:</p>
        </div>
    </header>

    <section>
        <div class="uk-section">
            <div class="uk-container">
                <div class="uk-column-1-2@l uk-text-justify">

                    <p>Vandalism has always been one of Wikipedia's biggest problems, yet there are only few automatic
                        countermeasures. Instead, volunteers spend their time in reverting vandalism edits---time, which
                        is not spend on improving other parts of the Wikipedia. The goal of this evaluation campaign is
                        to research and develop new, reliable ways to detect vandalism edits, which can be used to aid
                        the Wikipedians.</p>
                    <p>Vandalism is <a href="http://en.wikipedia.org/wiki/Wikipedia:Vandalism">defined</a> as "any
                        addition, removal, or change of content made in a <em>deliberate</em> attempt to compromise the
                        integrity of Wikipedia". Put another way, a vandalism edit is an edit made with bad intentions.
                    </p>
                    <p>Solutions to vandalism detection will resemble those of, e.g., spam detection. Hence, the
                        application of machine learning to this problem is straightforward which makes the engineering
                        of features for an edit model that discriminates vandalism edits from regular edits one of the
                        primary topics. You can use all features imaginable for your edit model, with one exception: <i>you
                            may not look into an edit's future</i>. I.e., to classify an edit, you may not analyze
                        succeeding edits on the same article to see what became of it. Such a feature would be unusable
                        in practice.</p>

                    <h3>Task</h3>
                    <p>Given a set of edits on Wikipedia articles, the task is to separate the ill-intentioned edits
                        from the well-intentioned edits.
                    </p>


                    <h3>Training Corpus</h3>
                    <p>To develop your approach, we provide you with a training corpus which comprises a set of edits on
                        Wikipedia articles. All of these edits have been manually annotated whether they constitue
                        vandalism or not.</p>
                    <p>
                        <a class="uk-button uk-button-primary"
                           href="https://www.uni-weimar.de/medien/webis/publications/papers/potthast_2010b.pdf">Learn
                            more »</a>
                        <a class="uk-button uk-button-primary" target="_blank"
                           href="https://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-10/pan10-data/pan10-wikipedia-vandalism-detection-training-corpus-2010-03-15.zip">Download
                            corpus</a>
                    </p>


                    <h3>Output</h3>
                    <p>
                        For all edits found in the evaluation corpora, your vandalism detector shall output a file
                        <code>classification.txt</code> as follows:
                    </p>
                    <pre class="prettyprint lang-py" style="overflow-x:auto">
26864258 27932250 V 0.92
28689695 87188208 R 0.50
85047080 85047157 V 0.67
80637222 91249168 R 0.43
...</pre>
                    <ul>
                        <li>
                            The first column is the edit's old revision ID.
                        </li>
                        <li>
                            The second column is the edit's new revision ID.
                        </li>
                        <li>
                            The third column denotes whether the edit is vandalism (V) or regular (R), as determined by
                            your classifier.
                        </li>
                        <li>
                            The fourth column denotes your classifier's confidence. Providing these confidence values is
                            optional.
                        </li>
                    </ul>


                    <h3>Performance Measures</h3>
                    <p>
                        Performance is measured using the receiver operating characteristics (ROC) [<a
                            href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank">Wikipedia</a>
                        | <a
                            href="https://web.archive.org/web/20110810030615/http://home.comcast.net/~tom.fawcett/public_html/papers/ROC101.pdf"
                            target="_blank">paper</a>]. More specifically, we measure the area under the ROC curve
                        (AUC), while the algorithm which maximizes the AUC performs best.
                    </p>


                    <h3>Test Corpus</h3>
                    <p>Once you finished tuning your approach to achieve satisfying performance on the training corpus,
                        you should run your software on the test corpus.</p>
                    <p>During the competition, the test corpus does not contain ground truth data that reveals whether
                        or not a suspicious document contains any plagiarized passages. To find out the performance of
                        your software on the test corpus, you must collect the output its and submit it as described
                        below.</p>
                    <p>After the competition, the test corpus is updated to include the ground truth data. This way, you
                        have all the neccessary data to evaluate your approach on your own, without submitting it's
                        output, yet being comparable to those who took part in the competition.</p>
                    <p>
                        <a class="uk-button uk-button-primary" target="_blank"
                           href="https://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-10/pan10-data/pan10-wikipedia-vandalism-detection-test-corpus-2010-05-16.zip">Download
                            corpus</a>
                    </p>


                    <h3>Submission</h3>
                    <p>To submit your test run for evaluation, we ask you to send a Zip archive containing the output of
                        your software when run on the test corpus to <a href="mailto:pan@webis.de">pan@webis.de</a>.</p>
                    <p>Should the Zip archive be too large to be sent via mail, please upload it to a file hoster of
                        your choosing and share a download link with us.</p>


                    <h3>Results</h3>
                    <p>The following table lists the performances achieved by the participating teams:</p>
                    <table class="uk-table uk-table-divider uk-table-small uk-table-hover" style="font-size:small;">
                        <thead>
                        <tr class="top">
                            <th colspan="7" style="text-align:center">Wikipedia Vandalism Detection Performance</th>
                        </tr>
                        <tr class="mid">
                            <th>ROC-AUC</th>
                            <th>Participant</th>
                        </tr>
                        </thead>
                        <tbody>
                        <tr>
                            <td>0.92236</td>
                            <td>S.M. Mola Velasco<br/>Private, Spain</td>
                        </tr>
                        <tr>
                            <td>0.90351</td>
                            <td>B.T. Adler*, L. de Alfaro° and I. Pye^<br/>*Fujitsu Labs of America, Inc., USA<br/>°Google,
                                Inc., and University of California Santa Cruz, USA<br/>^CloudFlare, Inc., USA
                            </td>
                        </tr>
                        <tr>
                            <td>0.89856</td>
                            <td>S. Javanmardi <span style="font-style:italic">et al.</span><br/>University of California
                                Irvine, USA
                            </td>
                        </tr>
                        <tr>
                            <td>0.89377</td>
                            <td>D. Chichkov<br/>SC Software Inc., USA</td>
                        </tr>
                        <tr>
                            <td>0.87990</td>
                            <td>L. Seaward<br/>University of Ottawa, Canada</td>
                        </tr>
                        <tr>
                            <td>0.87669</td>
                            <td>I. Heged&#x169;s*, R. Orm&aacute;ndi*, R. Farkas*, and M. Jelasity*<sup>,</sup>°<br/>*University
                                of Szeged, Hungary<br/>°Hungarian Academy of Sciences, Hungary
                            </td>
                        </tr>
                        <tr>
                            <td>0.85875</td>
                            <td>M. Harpalani, T. Phumprao, M. Bassi, M. Hart, and R. Johnson<br/>Stony Brook University,
                                USA
                            </td>
                        </tr>
                        <tr>
                            <td>0.84340</td>
                            <td>J. White and R. Maessen<br/>University of California Irvine, USA</td>
                        </tr>
                        <tr>
                            <td>0.65404</td>
                            <td>A. Iftene<br/>University of Iasi, Romania</td>
                        </tr>
                        </tbody>
                    </table>
                    <p>A more detailed analysis of the detection performances can be found in the overview paper
                        accompanying this task.</p>
                    <p><a class="uk-button uk-button-primary"
                          href="https://www.uni-weimar.de/medien/webis/publications/papers/stein_2010u.pdf#page=7">Learn
                        more »</a></p>


                    <h3>Related Work</h3>
                    <p>
                        On Wikipedia, there are a number of pages dealing with vandalism. The following pages offer a
                        good introduction as well as many links to other pages about vandalism detection policies and
                        tools:
                    </p>
                    <ul>
                        <li><a href="http://en.wikipedia.org/wiki/Wikipedia:Vandalism" target="_blank">Definition of
                            vandalism</a></li>
                        <li><a href="http://en.wikipedia.org/wiki/Wikipedia:Cleaning_up_vandalism" target="_blank">Vandalism
                            fighter's portal</a></li>
                        <li><a href="http://en.wikipedia.org/wiki/Wikipedia:Most_vandalized_pages" target="_blank">Most
                            vandalized pages</a></li>
                        <li><a href="http://en.wikipedia.org/w/api.php" target="_blank">Wikipedia API</a></li>
                    </ul>
                    <p>
                        Research on Wikipedia vandalism is still in its infancy. The following lists all related papers
                        up to now:
                    </p>
                    <ul>
                        <li>Si-Chi Chin, W. Nick Street, Padmini Srinivasan, and David Eichmann. Detecting Wikipedia
                            vandalism with active learning and statistical language models. Fourth Workshop on
                            Information Credibility on the Web (WICOW 2010), Raleigh, NC, April 2010.
                        </li>
                        <li>R. Stuart Geiger and David Ribes. The Work of Sustaining Order in Wikipedia: The Banning of
                            a Vandal. In CSCW'10: Proceedings of the ACM Conference on Computer Supported Cooperative
                            Work, pages 117-126, Savannah, Georgia, USA, 2010. ACM.
                        </li>
                        <li>Kelly Y. Itakura and Charles L. A. Clarke. Using Dynamic Markov Compression to Detect
                            Vandalism in the Wikipedia. In SIGIR'09: Proceedings of the 32nd International ACM SIGIR
                            Conference on Research and Development in Information Retrieval, pages 822-823, New York,
                            NY, USA, 2009. ACM.
                        </li>
                        <li>Martin Potthast. Crowdsourcing a Wikipedia Vandalism Corpus. In 33rd Annual International
                            ACM SIGIR Conference (to appear), Geneva, July 2010. ACM.
                        </li>
                        <li>Martin Potthast, Benno Stein, and Robert Gerling. Automatic Vandalism Detection in
                            Wikipedia. In ECIR'08: Proceedings of the 30th European Conference on IR Research, Glasgow,
                            volume 4956 LNCS of Lecture Notes in Computer Science, pages 663-668, Berlin Heidelberg New
                            York, 2008. Springer.
                        </li>
                        <li>Reid Priedhorsky, Jilin Chen, Shyong (Tony) K. Lam, Katherine Panciera, Loren Terveen, and
                            John Riedl. Creating, Destroying, and Restoring Value in Wikipedia. In Group'07: Proceedings
                            of the International Conference on Supporting Group Work, Sanibel Island, Florida, USA,
                            2007.
                        </li>
                        <li>Koen Smets, Bart Goethals, and Brigitte Verdonk. Automatic Vandalism Detection in Wikipedia:
                            Towards a Machine Learning Approach. In WikiAI'08: Proceedings of the Workshop on Wikipedia
                            and Artificial Intelligence: An Evolving Synergy, pages 43-48. AAAI Press, 2008.
                        </li>
                        <li>Andrew G. West, Sampath Kannan, and Insup Lee. Detecting Wikipedia Vandalism via
                            Spatio-Temporal Analysis of Revision Metadata. Technical Report MS-CIS-10-05, University of
                            Pennsylvania, 2010.
                        </li>
                    </ul>

                </div>
            </div>
        </div>  <!-- section -->

        <div class="uk-section uk-section-muted">
            <div class="uk-container">

                <h2>Task Chair</h2>
                <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                    {% include people-cards/potthast.html %}
                </div>

                <h2>Task Committee</h2>
                <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                    {% include people-cards/temporary.html url="https://weimar.webis.de" name="Teresa Holfeld"
                    picture="../pan10-figures/teresa.jpg" affiliation="Bauhaus Universität Weimar" %}
                    {% include people-cards/stein.html %}
                </div>
            </div>
            <div class="uk-container uk-padding-large uk-padding-remove-bottom">
                {% include organizations/clef-organizations-section.html year=2010 %}
            </div>
        </div>
    </section>
</main>
