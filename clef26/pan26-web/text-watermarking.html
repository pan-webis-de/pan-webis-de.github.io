---
layout: default
nav_active: shared-tasks
title: PAN at CLEF 2026 - Text Watermarking
description: PAN at CLEF 2026 - Text Watermarking
---
<nav class="uk-container">
<ul class="uk-breadcrumb">
<li><a href="../../index.html">PAN</a></li>
<li><a href="../../shared-tasks.html">Shared Tasks</a></li>
<li class="uk-disabled"><a href="#">Text Watermarking 2026</a></li>
</ul>
</nav>

<main class="uk-section uk-section-default">
    <div class="uk-container">
        <div class="uk-container uk-margin-small">
            <h1 class="uk-margin-remove-top">Text Watermarking 2026</h1>
            <ul class="uk-list">
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#synopsis">Synopsis</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#task-overview">Task Overview</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#data">Data</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#submission">Submission</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#evaluation">Evaluation</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#baselines">Baselines</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#leaderboard">Leaderboard</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#related-work">Related Work</a></li>
                <li><span data-uk-icon="chevron-down"></span><a class="uk-margin-small-right" href="#task-committee">Task Committee</a></li>
            </ul>
        </div>

        <div class="uk-container uk-margin-medium">

            <h2 id="synopsis">Synopsis</h2>
            <ul class="uk-list uk-list-bullet">
                <li>Task: Insert a watermark into a given text. Then, after we have attacked the text, detect the inserted watermark. </li>
                <li>Registration: [<a href="https://clef-labs-registration.dipintra.it/">CLEF labs</a>]</li>
                <li>Important dates:
                    <ul>
                        <li><strong>May 07, 2026:</strong> software submission</li>
                        <li><strong>May 28, 2026:</strong> participant notebook submission
                            [<a href="../../pan-notebook-paper-template/pan-notebook-paper-template.zip">template</a>]
                            [<a href="https://easychair.org/conferences/?conf=clef2026">submission</a>&nbsp; â€“ <em>select "Stylometry and Digital Text Forensics (PAN)"</em> ]</li>
                    </ul>
                </li>
                <li>Data: Political speeches [<a href="https://zenodo.org/records/18620130">download</a>] </li>
                <li>Evaluation Measures: Balanced Accuracy, BLEU, BERTScore </li>
<!--                <li>Baselines: TBA [<a href="">code</a>]</li>-->
	        </ul>
            
            
            <h2 id="task-overview">Task Overview</h2>
            <p>In the Text Watermarking task, participants are given a text and must insert a watermark into it. After submitting the watermark system, including a watermark detection algorithm, through <a href="https://www.tira.io/">TIRA</a>, the watermark system is run on the test dataset. The watermarked texts are then subjected to various attacks. The objective is to detect the watermark after the text has been attacked, thereby demonstrating its robustness against an attacker.</p>
            
            <p>The task is structured as follows:</p>

            <ol>
                <li>Develop a text watermarking system, that inserts a watermark into a text. You can use the provided training dataset for this purpose.</li>
                <li>Submit your watermarking system, including the watermark detection, through the <a href="https://www.tira.io/">Tira</a> platform.</li>
                <li>We will run your submitted watermarking system on our test dataset.</li>
                <li>We will then carry out attacks of varying severity on the watermarked texts from the test dataset.</li>
                <li>We will run your watermark detection system on the attacked texts to evaluate its performance in detecting watermarks.</li>
            </ol>

            <p>The watermarked text must remain semantically close to the original. Watermarked texts that deviate significantly in meaning from the original will be penalized during evaluation.</p>


            <h2 id="data">Data</h2>
            The dataset is available via <a href="https://zenodo.org/records/18620130">Zenodo</a>.

            <p>The training dataset is provided as a set of newline-delimited JSON files. The file format is as follows:</p>

            <pre class="prettyprint"><code class="lang-json">{"id": "9a28d103-7b2e-43da-b511-2efb5f91975f", "text": "..."}
{"id": "4fcae8a8-f5e6-4ccd-9dae-10b609a47cfc", "text": "..."}
...</code></pre>

            <p>The test dataset will have the exact same format.</p>

            <h2 id="submission">Submission</h2>
            <p>Participants will submit their systems as Docker images through the <a href="https://www.tira.io/">Tira</a> platform. It is not expected that submitted systems are actually <em>trained</em> on Tira, but they must be standalone and runnable on the platform without requiring contact to the outside world (evaluation runs will be sandboxed).</p>
            <p><b>Important:</b> As contact to the outside world is not possible in the TIRA environment, submissions cannot use online services such as ChatGPT or other online LLMs.</p>

            <p>The submitted software must be executable inside the container via a command line call. The script must take two arguments: an input file (an absolute path to the input JSONL file) and an output directory (an absolute path to where the results will be written):</p>

            <p>Within Tira, the input file will be called <code>dataset.jsonl</code>, so with the pre-defined Tira placeholders, your software should be invoked like this:</p>
            <pre class="prettyprint"><code class="lang-console">$ mySoftware $inputDataset/dataset.jsonl $outputDir</code></pre>

            <p>Within <code>$outputDir</code>, a single (!) file with the file extension <code>*.jsonl</code> must be created with the following format:</p>

            <pre class="prettyprint"><code class="lang-json">{"id": "bea8cccd-0c99-4977-9c1b-8423a9e1ed96", "label": 1.0}
{"id": "a963d7a0-d7e9-47c0-be84-a40ccc2005c7", "label": 0.0}
...</code></pre>
            

            <h2 id="evaluation">Evaluation</h2>
            <p>Systems will be evaluated with the following metrics:</p>

            <ul class="uk-list uk-list-bullet">
                <li>Overall score, here called Text Watermarking Fidelity (TWF). <code>TWF = max(BLEU, BERTScore) &middot; Balanced Accuracy</code></li>
                <li>Balanced Accuracy: The average of true positive rate and true negative rate.</li>
                <li>BLEU: Syntactic similarity of the watermarked text to the original text. Here, it is computed at sentence level and averaged over the full text.</li>
                <li>BERTScore: Semantic similarity between the watermarked text and the original text. Here, it is computed at sentence level and averaged over the full text.</li>
                <li>In addition, the confusion matrix is reported for calculating true/false positive/negative rates.</li>
            </ul>

            <p>The evaluator for the task will output the above measures as JSON like so:</p>
            <pre class="prettyprint"><code class="lang-json">{
    "twf": 0.878,
    "balanced_accuracy": 0.974,
    "bleu": 0.901,
    "bert-score": 0.85,
    "confusion": [
        [
            1211,
            66
        ],
        [
            27,
            2285
        ]
    ]
}</code></pre>

            <h2 id="baselines">Baselines</h2>
            <p>TBA</p>

            <h2 id="leaderboard">Leaderboard</h2>
            <p>TBD</p>
        </div>
    </div>

    <div class="uk-section uk-section-default">
        <div class="uk-container uk-margin-medium">
            <h2 id="related-work">Related Work</h2>
            <ul class="uk-list uk-list-bullet">
                <li>
                    John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and
Tom Goldstein. A watermark for large language models. In Andreas Krause,
Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and
Jonathan Scarlett, editors, International Conference on Machine Learning,
ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume 202 of Pro-
ceedings of Machine Learning Research, pages 1706117084. PMLR, 2023.
URL https://proceedings.mlr.press/v202/kirchenbauer23a.html
                </li>
                <li>
                    Yapei Chang, Kalpesh Krishna, Amir Houmansadr, John Wieting, and Mo-
hit Iyyer. Postmark: A robust blackbox watermark for large language
models. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen, edi-
tors, Proceedings of the 2024 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16,
2024, pages 89698987. Association for Computational Linguistics, 2024.
doi: 10.18653/V1/2024.EMNLP-MAIN.506. URL https://doi.org/10.
18653/v1/2024.emnlp-main.506.
                </li>
                <li>
                    Xuandong Zhao, Prabhanjan Vijendra Ananth, Lei Li, and Yu-Xiang Wang.
Provable robust watermarking for ai-generated text. In The Twelfth Interna-
tional Conference on Learning Representations, ICLR 2024, Vienna, Aus-
tria, May 7-11, 2024. OpenReview.net, 2024. URL https://openreview.
net/forum?id=SsmT8aO45L.
                </li>
                <li>
                    Yijian Lu, Aiwei Liu, Dianzhi Yu, Jingjing Li, and Irwin King. An entropy-
based text watermarking detection method. In Lun-Wei Ku, Andre Martins,
and Vivek Srikumar, editors, Proceedings of the 62nd Annual Meeting of
the Association for Computational Linguistics (Volume 1: Long Papers),
ACL 2024, Bangkok, Thailand, August 11-16, 2024, pages 1172411735.
Association for Computational Linguistics, 2024. doi: 10.18653/V1/2024.
ACL-LONG.630. URL https://doi.org/10.18653/v1/2024.acl-long.
630.
                </li>
                <li>
                    Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, Sangdoo
Yun, Jamin Shin, and Gunhee Kim. Who wrote this code? watermarking
for code generation. In Lun-Wei Ku, Andre Martins, and Vivek Sriku-
mar, editors, Proceedings of the 62nd Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), ACL 2024, Bangkok,
Thailand, August 11-16, 2024, pages 48904911. Association for Compu-
tational Linguistics, 2024. doi: 10.18653/V1/2024.ACL-LONG.268. URL
https://doi.org/10.18653/v1/2024.acl-long.268.
                </li>
                <li>
                    Aiwei Liu, Leyi Pan, Yijian Lu, Jingjing Li, Xuming Hu, Lijie Wen, Irwin King,
and Philip S. Yu. A survey of text watermarking in the era of large language
models. CoRR, abs/2312.07913, 2023. doi: 10.48550/ARXIV.2312.07913.
URL https://doi.org/10.48550/arXiv.2312.07913.
                </li>
            </ul>

            <h2 id="task-committee">Task Committee</h2>
            <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                {% include people-cards/plutz.html %}
                {% include people-cards/jakoby.html %}
                {% include people-cards/bevendorff.html %}
                {% include people-cards/potthast.html %}
                {% include people-cards/stein.html %}
            </div>
            <div class="uk-container uk-padding-large uk-padding-remove-bottom">
                {% include organizations/clef-organizations-section.html year=2026 %}
            </div>
        </div>
    </div>
</main>
